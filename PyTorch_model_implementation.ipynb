{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "mount_file_id": "1Y6TTIeMIgPZ6oh0w1K6IA_ddZ65QjEWC",
      "authorship_tag": "ABX9TyMnXgBqJ4RONONGcifXm5au",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/salama4ai/AI-project/blob/main/PyTorch_model_implementation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# This notebook is for preprocessing the data and implementing the model using Pytorch library"
      ],
      "metadata": {
        "id": "5-w-RKgEyo8V"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "ajVUf3e6aaIk"
      },
      "outputs": [],
      "source": [
        "# importing the libraries\n",
        "import os\n",
        "import random\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from matplotlib import pyplot as plt\n",
        "import time\n",
        "from tqdm import tqdm\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import Dataset, DataLoader, TensorDataset\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.compose import make_column_transformer\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.preprocessing import OneHotEncoder, MinMaxScaler, OrdinalEncoder, StandardScaler\n",
        "from sklearn.metrics import mean_squared_error, r2_score"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# this line to select the GPU as an engine for doing the work if it's possible, else it selects the 'cpu'\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "\n",
        "# This function to be able to reproduce the same numbers in the future, by fixing\n",
        "# the algorithms parameters that lead to generate the same random numbers\n",
        "\n",
        "# fix random number generation aka regenerate the same random numbers every time (such as weight and bias initialization )\n",
        "def set_random_seed(seed=7, deterministic=True):\n",
        "    \"\"\"Set random seed, for python, numpy, pytorch\n",
        "\n",
        "    Args:\n",
        "        seed (int): Seed to be used.\n",
        "        deterministic (bool): Whether to set the deterministic option for\n",
        "            CUDNN backend, i.e., set `torch.backends.cudnn.deterministic`\n",
        "            to True and `torch.backends.cudnn.benchmark` to False.\n",
        "            Default: True.\n",
        "    \"\"\"\n",
        "    random.seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed_all(seed)\n",
        "    if deterministic:\n",
        "        torch.backends.cudnn.deterministic = True\n",
        "        torch.backends.cudnn.benchmark = False\n",
        "seed=7\n",
        "set_random_seed(seed=seed)"
      ],
      "metadata": {
        "id": "KmmhSZl2NboD"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# read the csv data file\n",
        "x = pd.read_csv(\"/content/drive/MyDrive/Mabrains-project/Mabrains-data/mabrains.csv\")"
      ],
      "metadata": {
        "id": "2SVcNrWoadhX"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# show the first 5 rows\n",
        "x.head()"
      ],
      "metadata": {
        "id": "AbLzHvfEb7Nf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "outputId": "8f8c6c6c-feb6-4977-af8b-6eb6b325d3c2"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "    vds  L(um)  W(um)  vgs  vsb corner    id(uA)\n",
              "0 -0.45    8.0   0.84  0.0  0.0     tt  0.034866\n",
              "1 -0.40    8.0   0.84  0.0  0.0     tt  0.009451\n",
              "2 -0.35    8.0   0.84  0.0  0.0     tt  0.002331\n",
              "3 -0.30    8.0   0.84  0.0  0.0     tt  0.000532\n",
              "4 -0.25    8.0   0.84  0.0  0.0     tt  0.000111"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-5dbad2d6-6ede-4141-9b42-d40dfd746984\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>vds</th>\n",
              "      <th>L(um)</th>\n",
              "      <th>W(um)</th>\n",
              "      <th>vgs</th>\n",
              "      <th>vsb</th>\n",
              "      <th>corner</th>\n",
              "      <th>id(uA)</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>-0.45</td>\n",
              "      <td>8.0</td>\n",
              "      <td>0.84</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>tt</td>\n",
              "      <td>0.034866</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>-0.40</td>\n",
              "      <td>8.0</td>\n",
              "      <td>0.84</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>tt</td>\n",
              "      <td>0.009451</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>-0.35</td>\n",
              "      <td>8.0</td>\n",
              "      <td>0.84</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>tt</td>\n",
              "      <td>0.002331</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>-0.30</td>\n",
              "      <td>8.0</td>\n",
              "      <td>0.84</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>tt</td>\n",
              "      <td>0.000532</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>-0.25</td>\n",
              "      <td>8.0</td>\n",
              "      <td>0.84</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>tt</td>\n",
              "      <td>0.000111</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-5dbad2d6-6ede-4141-9b42-d40dfd746984')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-5dbad2d6-6ede-4141-9b42-d40dfd746984 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-5dbad2d6-6ede-4141-9b42-d40dfd746984');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-dc051195-af6f-4abb-8be4-ecaf396cdea5\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-dc051195-af6f-4abb-8be4-ecaf396cdea5')\"\n",
              "            title=\"Suggest charts.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-dc051195-af6f-4abb-8be4-ecaf396cdea5 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Preprocessing"
      ],
      "metadata": {
        "id": "UMOaK3MKqgV9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1- i will convert corner column into one hot encoded columns\n",
        "\n",
        "2- i will apply on W(um) and L(um) columns, to make sure that the high values in these two columns will not dominate the model calculations and thus the model decision just due to containing high values"
      ],
      "metadata": {
        "id": "VpxcfrGudprU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# separate the output(or label or target) column from the features(input) columns\n",
        "# where 'x' the feature columns,\n",
        "# 'y' is the target column\n",
        "y = x.pop(\"id(uA)\")\n",
        "\n",
        "# split the train and test sets and the coresponding labels\n",
        "xtrain_unprocessed, xtest_unprocessed, ytrain, ytest = train_test_split(x, y, test_size=0.21, random_state=seed, shuffle=True)"
      ],
      "metadata": {
        "id": "IjAwutBPM2iW"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# apply the needed transformations over the determined columns\n",
        "col_trans1 = make_column_transformer((\"passthrough\", ['vgs', 'vds', 'vsb']),\n",
        "                                    (OneHotEncoder(handle_unknown=\"infrequent_if_exist\"), ['corner']),\n",
        "                                    (MinMaxScaler(), ['L(um)', 'W(um)']),\n",
        "                                     remainder=\"drop\",\n",
        "                                     n_jobs=-1)\n",
        "\n",
        "# apply the needed transformations over the training data\n",
        "xtrain = col_trans1.fit_transform(xtrain_unprocessed)\n",
        "\n",
        "# xtest = col_trans1.transform(xtest_unprocessed)#i can do this step now, but i will delay doing this step, to collect all test data preprocessing in one cell"
      ],
      "metadata": {
        "id": "9PL3hFx-Llwc"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class CollectedData(Dataset):\n",
        "    '''create the class to deal with the data convert them into torch tensors, getting the data item and getting the length of the data'''\n",
        "\n",
        "    def __init__(self, x, y):\n",
        "        self.data = torch.tensor(x)\n",
        "        self.label = torch.tensor(y.values)\n",
        "        self.n_smpl = x.shape[0]\n",
        "\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        '''return the data sample given the index'''\n",
        "\n",
        "        # return the features and the corresponding label of the given index\n",
        "        # i convert them to float to solve an error appears while train the model\n",
        "        return self.data[idx].float(), self.label[idx].float()\n",
        "\n",
        "    def __len__(self):\n",
        "        '''function to return the length of the dataset'''\n",
        "\n",
        "        # return the length of the dataset\n",
        "        return self.n_smpl\n",
        "\n",
        "#compine the features and the corresponding labels into one object\n",
        "train_set = CollectedData(xtrain, ytrain)\n",
        "\n",
        "# test_set = CollectedData(xtest, ytest)#i can do this step now, but i will delay doing this step, to collect all test data preprocessing in one cell"
      ],
      "metadata": {
        "id": "P6rGheIAArUu"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## almost the same result of the brevious cell, using another way.\n",
        "# # train_set, test_set = torch.utils.data.random_split(dataset, [len(dataset)-test_len, int(len(dataset)*0.2)])\n",
        "\n",
        "# train_labels = torch.tensor(ytrain.values.astype(np.float32))\n",
        "# # test_labels = torch.tensor(ytest.values.astype(np.float32)) #i can do this step now, but i will delay doing this step, to collect all test data preprocessing in one cell\n",
        "# train_input = torch.tensor(xtrain.values.astype(np.float32))\n",
        "# # test_input = torch.tensor(xtest.values.astype(np.float32)) #i can do this step now, but i will delay doing this step, to collect all test data preprocessing in one cell\n",
        "\n",
        "# train_set = TensorDataset(train_input, train_labels)\n",
        "# # test_set = TensorDataset(test_input, test_labels) #i can do this step now, but i will delay doing this step, to collect all test data preprocessing in one cell\n"
      ],
      "metadata": {
        "id": "VlgjN9U9A4lc"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# set the batch size\n",
        "batch_size = 4096\n",
        "\n",
        "train_loader = DataLoader(dataset=train_set, shuffle=True, batch_size=batch_size)\n",
        "# test_loader = DataLoader(dataset=test_set, batch_size=batch_size) #i can do this step now, but i will delay doing this step, to collect all test data preprocessing in one cell"
      ],
      "metadata": {
        "id": "S1AcLhuoA5Qz"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class network(nn.Module):\n",
        "    '''create the structure of the model'''\n",
        "\n",
        "    def __init__(self, in_features=10, out_features=1):\n",
        "        '''like class constructor function'''\n",
        "\n",
        "        super().__init__()\n",
        "        # the fully connected layers\n",
        "        self.fc1 = nn.Linear(in_features, 20)\n",
        "        self.fc2 = nn.Linear(20, 20)\n",
        "        self.fc3 = nn.Linear(20, 20)\n",
        "        self.fc4 = nn.Linear(20, 20)\n",
        "        self.fc5 = nn.Linear(20, 20)\n",
        "        self.fc6 = nn.Linear(20, out_features)\n",
        "\n",
        "        # initialize the model parameters(weights, bias)\n",
        "        self.initialize_weights()\n",
        "\n",
        "\n",
        "    def forward(self, inpt):\n",
        "      '''this the the forward path of the model'''\n",
        "\n",
        "        # relu activation function over the output of the fully connected layed output\n",
        "        out = F.relu(self.fc1(inpt))\n",
        "\n",
        "        # leaky_relu activation function over the output of the fully connected layed output\n",
        "        out = F.leaky_relu(self.fc2(out))\n",
        "\n",
        "        # out = F.leaky_relu(self.fc3(out))\n",
        "        # out = F.leaky_relu(self.fc4(out))\n",
        "        # out = F.leaky_relu(self.fc5(out))\n",
        "        out = ((self.fc6(out)))\n",
        "        # out = F.softmax((self.fc6(out)), dim=1)\n",
        "\n",
        "        # return the result\n",
        "        return out\n",
        "\n",
        "    def initialize_weights(self):\n",
        "      '''initialize the model parameters(W, b)'''\n",
        "\n",
        "        for m in self.modules():\n",
        "            if isinstance(m, nn.Linear):\n",
        "                nn.init.kaiming_uniform_(m.weight)\n",
        "                nn.init.constant_(m.bias, 0)\n"
      ],
      "metadata": {
        "id": "36HQNa8zBA_0"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# calculating accuracy\n",
        "@torch.no_grad()\n",
        "def calculate_accuracy(model, data_loader=train_loader):\n",
        "    '''this function is to calculate the loss or the error between the true(correct) labels and the predicted labels'''\n",
        "\n",
        "    # Set the model to eval mode while validating\n",
        "    model.eval()\n",
        "\n",
        "    # initialize error to zero\n",
        "    error = 0\n",
        "\n",
        "    # starting the loop over data\n",
        "    for data, labels in data_loader:\n",
        "\n",
        "        # transfering data to cuda\n",
        "        data = data.to(device=device)\n",
        "\n",
        "        # transfering labels to cuda\n",
        "        labels = labels.to(device=device)\n",
        "\n",
        "        # get the model predictions of the given data\n",
        "        preds = model(data)\n",
        "\n",
        "        # MSE_loss += F.mse_loss(preds, labels)\n",
        "        num_samples += len(labels)\n",
        "\n",
        "        error += r2_score(labels, preds)\n",
        "\n",
        "    # return the model to the train mode.\n",
        "    model.train()\n",
        "\n",
        "    # return the result\n",
        "    return (acc/(i+1)).detach().item()"
      ],
      "metadata": {
        "id": "oIAP1h5YBAzE"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# initializing the model\n",
        "model = network().to(device)\n",
        "\n",
        "#the Learning Rate\n",
        "lr = 0.5\n",
        "\n",
        "# loss initializing\n",
        "criterion = nn.MSELoss()\n",
        "\n",
        "#optimizer initializing\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
        "\n",
        "#learning-rate schedular initialization\n",
        "schedular = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, factor=0.999999999999, patience=9e99, verbose=True)\n",
        "\n",
        "# print the model structure\n",
        "model"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lLNRFyUxBKVS",
        "outputId": "35c85ec4-5e29-4306-9988-f0d29c82b74d"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "network(\n",
              "  (fc1): Linear(in_features=10, out_features=20, bias=True)\n",
              "  (fc2): Linear(in_features=20, out_features=20, bias=True)\n",
              "  (fc3): Linear(in_features=20, out_features=20, bias=True)\n",
              "  (fc4): Linear(in_features=20, out_features=20, bias=True)\n",
              "  (fc5): Linear(in_features=20, out_features=20, bias=True)\n",
              "  (fc6): Linear(in_features=20, out_features=1, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# determine number of calculations\n",
        "num_epochs = 3\n",
        "\n",
        "# define the training function.\n",
        "def train_model(num_epochs, data_loader=train_loader):\n",
        "\n",
        "    # set the number of batches to be the length of 'data_loader'\n",
        "    num_batches = len(data_loader)\n",
        "\n",
        "    # print the hyperparameters informations that the model going to train based on.\n",
        "    print(f\"\"\"batch_size = {batch_size} \\n starting learning rate = {lr} \\n number of epochs = {num_epochs}\\\n",
        "    \\n number of batches = {num_batches} \\n model = {model}, \\n criterion={criterion}, \\n optimizer={optimizer}\"\"\")\n",
        "\n",
        "    # starting training loop epochs\n",
        "    result_train_acc, result_test_acc = [], []\n",
        "\n",
        "    # start the epochs loop\n",
        "    for epoch in range(num_epochs):\n",
        "\n",
        "        # printing out the time which the model starts, to be able to calculate the it take\n",
        "        start_time = time.time()\n",
        "\n",
        "        # initialize progress function that display the progress of the training.\n",
        "        progress = tqdm(enumerate(data_loader), total=num_batches, leave=True)\n",
        "\n",
        "        # starting the training loop for each epoch\n",
        "        for batch_idx, (data, labels) in progress:\n",
        "\n",
        "            # convert data to device\n",
        "            data = data.to(device=device)\n",
        "\n",
        "            # convert labels to device\n",
        "            labels = labels.to(device=device)\n",
        "\n",
        "            # calculate the predictions.\n",
        "            preds = model(data)\n",
        "\n",
        "            # calculate the loss.\n",
        "            loss = criterion(preds, labels)\n",
        "\n",
        "            # back propagation calculations\n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "\n",
        "            # optimization step\n",
        "            optimizer.step()\n",
        "\n",
        "            # determine the information to be showed while training progress and show it\n",
        "            progress.set_description(f\"epoch [{1+epoch}/{num_epochs}], loss={loss.item():0.4f}\")\n",
        "            progress.set_postfix()\n",
        "\n",
        "        # calculate the training accuracy\n",
        "        train_acc = calculate_accuracy(model, data_loader=train_loader)\n",
        "\n",
        "        # calculate the test accuracy\n",
        "        test_acc = calculate_accuracy(model, data_loader=test_loader)\n",
        "\n",
        "        # take learning-rate schedular step\n",
        "        schedular.step(test_acc)\n",
        "\n",
        "        # printing the important information about the training progress\n",
        "        print(f\"after {1+epoch} epoch, train_acc = {train_acc*100:.2f}%, test_acc = {test_acc*100:.2f}%,\\\n",
        "        time_elapsed = {((time.time()-start_time)/60):.1f} minuts. \\n\",\"-\"*139)\n",
        "\n",
        "        # add the training accuracy to a list to be able to visulaize the over all progress after the training completed\n",
        "        result_train_acc += [train_acc]\n",
        "\n",
        "        # add the test accuracy to a list to be able to visulaize the over all progress after the training completed\n",
        "        result_test_acc += [test_acc]\n",
        "\n",
        "        # stop the training in case the model reached to the optimum accuracy even if the epochs didn't completed\n",
        "        if test_acc==0.1 and train_acc==0.1:\n",
        "            return result_train_acc, result_test_acc\n",
        "\n",
        "    # return result_train_acc, result_test_acc after the training completed\n",
        "    return result_train_acc, result_test_acc\n",
        "\n",
        "# call the training function\n",
        "result_train_acc, result_test_acc = train_model(num_epochs, data_loader=train_loader)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eJmx9uZcBKPn",
        "outputId": "e0d491a6-7e75-4328-b929-54f8b3a65d54"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "batch_size = 4096 \n",
            " starting learning rate = 0.5 \n",
            " number of epochs = 3    \n",
            " number of batches = 169 \n",
            " model = network(\n",
            "  (fc1): Linear(in_features=10, out_features=20, bias=True)\n",
            "  (fc2): Linear(in_features=20, out_features=20, bias=True)\n",
            "  (fc3): Linear(in_features=20, out_features=20, bias=True)\n",
            "  (fc4): Linear(in_features=20, out_features=20, bias=True)\n",
            "  (fc5): Linear(in_features=20, out_features=20, bias=True)\n",
            "  (fc6): Linear(in_features=20, out_features=1, bias=True)\n",
            "), \n",
            " criterion=MSELoss(), \n",
            " optimizer=Adam (\n",
            "Parameter Group 0\n",
            "    amsgrad: False\n",
            "    betas: (0.9, 0.999)\n",
            "    capturable: False\n",
            "    differentiable: False\n",
            "    eps: 1e-08\n",
            "    foreach: None\n",
            "    fused: None\n",
            "    lr: 0.5\n",
            "    maximize: False\n",
            "    weight_decay: 0\n",
            ")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/169 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([4096])) that is different to the input size (torch.Size([4096, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n",
            "epoch [1/3], loss=1426669.2500:  99%|█████████▉| 168/169 [00:18<00:00, 10.62it/s]/usr/local/lib/python3.10/dist-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([347])) that is different to the input size (torch.Size([347, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n",
            "epoch [1/3], loss=1358533.0000: 100%|██████████| 169/169 [00:18<00:00,  9.07it/s]\n",
            "<ipython-input-45-50ed07d1bc29>:12: UserWarning: Using a target size (torch.Size([4096])) that is different to the input size (torch.Size([4096, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  loss += F.mse_loss(preds, labels)\n",
            "<ipython-input-45-50ed07d1bc29>:12: UserWarning: Using a target size (torch.Size([347])) that is different to the input size (torch.Size([347, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  loss += F.mse_loss(preds, labels)\n",
            "<ipython-input-45-50ed07d1bc29>:12: UserWarning: Using a target size (torch.Size([2789])) that is different to the input size (torch.Size([2789, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  loss += F.mse_loss(preds, labels)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "after 1 epoch, train_acc = 25626255360.00%, test_acc = 6765890560.00%,        time_elapsed = 0.7 minuts. \n",
            " -------------------------------------------------------------------------------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch [2/3], loss=1655153.7500: 100%|██████████| 169/169 [00:33<00:00,  5.06it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "after 2 epoch, train_acc = 25696612352.00%, test_acc = 6773016064.00%,        time_elapsed = 0.9 minuts. \n",
            " -------------------------------------------------------------------------------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch [3/3], loss=1847890.0000: 100%|██████████| 169/169 [00:16<00:00, 10.06it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "after 3 epoch, train_acc = 25586989056.00%, test_acc = 6757296128.00%,        time_elapsed = 0.6 minuts. \n",
            " -------------------------------------------------------------------------------------------------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# printing the maximum training accuracy and maximum testing accuracy the model reached\n",
        "print(f\"maximun training accuracy={(max(result_train_acc)):.2f}%\\nmaximun test accuracy={(max(result_test_acc)):.2f}%\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2ONGH5gBBKIQ",
        "outputId": "88d62a69-5bf9-4a91-81ad-f0d6dc301172"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "maximun training accuracy=256966128.00%\n",
            "maximun test accuracy=67730160.00%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### plot the overall training and testing accuracy progress"
      ],
      "metadata": {
        "id": "wQMI2xqKQgUH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# convert the train accuracy list into numpy array.\n",
        "train_line_val = np.array([val.cpu() for val in result_train_acc]) # just replace val with val.cpu() if output is cuda\n",
        "# convert the train accuracy list into numpy array.\n",
        "test_line_val = np.array([val.cpu() for val in result_test_acc]) # just replace val with val.cpu() if output is cuda\n",
        "\n",
        "# plot the progress of training accuracy over epochs.\n",
        "train_line, = plt.plot((range(len(train_line_val))), train_line_val, label=\"train accuracy\", marker=\"*\", linewidth=3)\n",
        "# plot the progress of testing accuracy over epochs.\n",
        "test_line, = plt.plot((range(len(test_line_val))), test_line_val, label=\"test accuracy\", marker=\"o\", linewidth=1)\n",
        "\n",
        "# set the legend parameters.\n",
        "plt.legend(loc=\"best\", handles=[train_line, test_line])\n",
        "# write the figure title.\n",
        "plt.title(\"train & test accuracy\")\n",
        "\n",
        "# write the label of x axis.\n",
        "plt.xlabel(\"epochs\")\n",
        "# write the label of y axis.\n",
        "plt.ylabel(\"accuracy percentage\")\n",
        "\n",
        "# add grid to the figure\n",
        "plt.grid()\n",
        "# to show the figure and remove any unwanted appered words\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 251
        },
        "id": "HWV83STLBJ-J",
        "outputId": "c356793b-7aca-41db-8a63-01b88462bffb"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-17-c1cac13299ec>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# plot the overall training and testing accuracy progress\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtrain_line_val\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mval\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mval\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mresult_train_acc\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# just replace val with val.cpu() if output is cuda\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mtest_line_val\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mval\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mval\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mresult_test_acc\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# just replace val with val.cpu() if output is cuda\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mtrain_line\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_line_val\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_line_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"train accuracy\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmarker\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"*\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlinewidth\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'result_train_acc' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### make the preprocessing steps on the test data\n"
      ],
      "metadata": {
        "id": "J5ku-KrPRq4R"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# apply the needed transformations over testing data.\n",
        "xtest = col_trans1.transform(xtest_unprocessed)\n",
        "\n",
        "# compine features and the corresponding labels in an object.\n",
        "test_set = CollectedData(xtest, ytest)\n",
        "\n",
        "# # almost the same result of the brevious cell, using another way.\n",
        "# # train_set, test_set = torch.utils.data.random_split(dataset, [len(dataset)-test_len, int(len(dataset)*0.2)])\n",
        "\n",
        "# test_labels = torch.tensor(ytest.values.astype(np.float32))\n",
        "# test_input = torch.tensor(xtest.values.astype(np.float32))\n",
        "# test_set = TensorDataset(test_input, test_labels)\n",
        "\n",
        "# split the test data into batches to be eaisly to deal with.\n",
        "test_loader = DataLoader(dataset=test_set, batch_size=batch_size)"
      ],
      "metadata": {
        "id": "4XOgFVHsNapw"
      },
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "vDSDRuhigAsK"
      },
      "execution_count": 50,
      "outputs": []
    }
  ]
}